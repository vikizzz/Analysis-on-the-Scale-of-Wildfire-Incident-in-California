{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COGS 108 - EDA Checkpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Names\n",
    "\n",
    "- Jiayi Zhao\n",
    "- Wenbo Hu\n",
    "- Yiyun Huang\n",
    "- Xiaotong Zeng"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='research_question'></a>\n",
    "# Research Question"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is there a statistically significant relationship between the scale (burning area) of wildfire and climate variables in California that are associated with global warming such as relative humidity level, temperature and wind speed? Additionally, how can we utilize these climate variables to predict the wildfire event in California and the scale of wildfire?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import pandas to read csv file and manage heterogenous data\n",
    "import pandas as pd\n",
    "\n",
    "# Import numpy to store numeric information and perform numerical analysis\n",
    "import numpy as np\n",
    "\n",
    "# Import seaborn and matplotlib to visualize data\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Import numpy to store numeric information and perform numerical analysis\n",
    "import numpy as np\n",
    "\n",
    "# Import seaborn and matplotlib to visualize data\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#Import scipy to gather statistics\n",
    "from scipy import stats\n",
    "\n",
    "# Import patsy and statsmodels for regression analysis\n",
    "import patsy\n",
    "import statsmodels.api as sm\n",
    "\n",
    "import warnings\n",
    "\n",
    "import shutil\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the three data sets that we need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the California wildfire incidents data set in data frame\n",
    "# We get this data set from Kaggle (https://www.kaggle.com/ananthu017/california-wildfire-incidents-20132020)\n",
    "wildfire = pd.read_csv(\"California_Fire_Incidents.csv\")\n",
    "\n",
    "\n",
    "# Load the US weather station ID data set in data frame\n",
    "# We get the Integrated Surface Data (ISD) station list from ncdc.noaa.gov\n",
    "station = pd.read_csv(\"https://www1.ncdc.noaa.gov/pub/data/noaa/isd-history.csv\")\n",
    "\n",
    "\n",
    "# Load the US weather daily data set from 2013 to 2019 in data frame\n",
    "# We get this data from ncei.noaa.gov and download to the local.\n",
    "# (https://www.ncei.noaa.gov/data/global-summary-of-the-day/archive/)\n",
    "for dirname, _, filenames in os.walk('/Users/wenbohu/Desktop/Weather'):\n",
    "    for filename in filenames:\n",
    "        print((os.path.join(dirname, filename)))\n",
    "        \n",
    "# get all subdiretory of all tables\n",
    "file_dict ={}\n",
    "for path, dirs, files in os.walk('/Users/wenbohu/Desktop/Weather', topdown=False):\n",
    "    file_dict[path]=files\n",
    "    \n",
    "paths = list(file_dict.keys())\n",
    "\n",
    "events = []\n",
    "for path in paths:\n",
    "    events += [os.path.join(path,file) for file in file_dict[path]]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we have three data set, we choose to clean them seperatly and then merge these dataset by locations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First, we clean the California wildfire incidents data set\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we only need the dates, acres burned (scale), and county name for the following analysis, we update these information back to 'wildfire'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete the irrelevant columns\n",
    "wildfire = wildfire[['AcresBurned','Started','Counties', 'Latitude', 'Longitude']]\n",
    "\n",
    "# change the started time into date\n",
    "#wildfire['Started'] = pd.to_datetime(wildfire['Started'])\n",
    "wildfire['Started'] = [x[0:10] for x in wildfire['Started']]\n",
    "\n",
    "# change the 'Started' column name into 'Date'\n",
    "wildfire = wildfire.rename({'Started':'Date'}, axis='columns')\n",
    "\n",
    "#drop the null values \n",
    "wildfire['Latitude'] = wildfire['Latitude'].apply(lambda x: np.nan if x == 0 else x)\n",
    "wildfire = wildfire.dropna().reset_index(drop=True) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now take a look on the wildfire dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wildfire.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Second, clean the Integrated Surface Data (ISD) station list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since the weather station ID is a combination of column 'USAF' and 'WBAN',\n",
    "# we combine these two columns into a new column called 'ID'\n",
    "station['ID']= station['USAF'].astype(str) + station['WBAN'].astype(str)\n",
    "\n",
    "# we only analyze California weather\n",
    "station = station[(station['STATE']=='CA') & (station['CTRY']=='US')].reset_index(drop=True)\n",
    "\n",
    "# station only need to include the ID and the nameof the station\n",
    "pd.set_option(\"max_rows\", None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now take a look on the station dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "station.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Thrid, we merge the wildfire and station ID dataframes by matching the LATITUDE and LONGTITUDE of the wildfire incident locations and weather stations. \n",
    "We compare each error index (0.1, 0.2, 0.3, 0.5) in order to find which diameter we should choose for more unique stations is determined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IDlist = []\n",
    "for i,j in wildfire.iterrows():\n",
    "    before = len(IDlist)\n",
    "    for a,b in station.iterrows():\n",
    "        #about 50km * 40km (just for first time test then tried 0.3, 0.1, and 0.2)\n",
    "        if (((b['LAT'] <= j['Latitude'] + 0.2) and (b['LAT'] >= j['Latitude'] - 0.2)) \n",
    "        and (( b['LON'] <= j['Longitude'] + 0.2) and ( b['LON'] >= j['Longitude'] - 0.2))):\n",
    "            IDlist.append(b['ID'])\n",
    "            break\n",
    "    after = len(IDlist)\n",
    "    if (before == after):\n",
    "        IDlist.append(\"Not_Found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0.5-95 0.3-119 0.1-119 0.2-127(THIS IS THE BEST!!!!)\n",
    "# when 0.1 it's also 119 but lots of not found values\n",
    "unique = []\n",
    "for x in IDlist:\n",
    "    if x not in unique:\n",
    "        unique.append(x)\n",
    "print(len(unique))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we create a dataframe called 'matched_wildfire' that consists the scale, date, county name, latitude, and longitude of the wildfire incidents and the weather station ID in that incident area."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IDlist = []\n",
    "row_fire = []\n",
    "row_ID =[]\n",
    "\n",
    "# create a new dataframe to store these matched data\n",
    "matched_wildfire = pd.DataFrame(columns=wildfire.columns)\n",
    "\n",
    "# iterate the rows in wildfire and station to find the matched data\n",
    "for i,j in wildfire.iterrows():\n",
    "    for a,b in station.iterrows():\n",
    "        if (((b['LAT'] <= j['Latitude'] + 0.2) and (b['LAT'] >= j['Latitude'] - 0.2)) \n",
    "        and (( b['LON'] <= j['Longitude'] + 0.2) and ( b['LON'] >= j['Longitude'] - 0.2))):\n",
    "            IDlist.append(b['ID'])\n",
    "            row_ID.append(b['ID'])\n",
    "            row_fire.append(list(j))\n",
    "            break\n",
    "            \n",
    "matched_wildfire = matched_wildfire.append(pd.DataFrame(row_fire,columns=wildfire.columns))\n",
    "matched_wildfire = matched_wildfire.assign(ID=row_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, take a look on the matched_wildfire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matched_wildfire.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Analysis & Results (EDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carry out EDA on your dataset(s); Describe in this section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## YOUR CODE HERE\n",
    "## FEEL FREE TO ADD MULTIPLE CELLS PER SECTION"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
